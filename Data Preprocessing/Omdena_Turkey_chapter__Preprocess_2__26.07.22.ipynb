{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e640471",
   "metadata": {},
   "source": [
    "# Data Preprocessing Turkey Earthquake data (Omdena TR project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5820fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad0bfa1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Origin Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Depth(km)</th>\n",
       "      <th>xM</th>\n",
       "      <th>MD</th>\n",
       "      <th>ML</th>\n",
       "      <th>Mw</th>\n",
       "      <th>Ms</th>\n",
       "      <th>Mb</th>\n",
       "      <th>Type</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>is_out_of_Turkey</th>\n",
       "      <th>id</th>\n",
       "      <th>ID_</th>\n",
       "      <th>NAME1_</th>\n",
       "      <th>NAME2_</th>\n",
       "      <th>PARTS_</th>\n",
       "      <th>POINTS_</th>\n",
       "      <th>LENGTH_</th>\n",
       "      <th>AREA_</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Date_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900.09.20</td>\n",
       "      <td>00:00:01.00</td>\n",
       "      <td>37.8</td>\n",
       "      <td>29.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ke</td>\n",
       "      <td>DENIZLI (DENIZLI) [North East  2.3 km]</td>\n",
       "      <td>DENIZLI</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASITUR003002002</td>\n",
       "      <td>Denizli</td>\n",
       "      <td>Denizli</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>364.9901</td>\n",
       "      <td>4621.875</td>\n",
       "      <td>POINT (29.1 37.8)</td>\n",
       "      <td>North East  2.3 km</td>\n",
       "      <td>1900-09-20 00:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1904.01.01</td>\n",
       "      <td>11:38:00.00</td>\n",
       "      <td>37.8</td>\n",
       "      <td>29.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Ke</td>\n",
       "      <td>DENIZLI (DENIZLI) [North East  2.3 km]</td>\n",
       "      <td>DENIZLI</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASITUR003002002</td>\n",
       "      <td>Denizli</td>\n",
       "      <td>Denizli</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>364.9901</td>\n",
       "      <td>4621.875</td>\n",
       "      <td>POINT (29.1 37.8)</td>\n",
       "      <td>North East  2.3 km</td>\n",
       "      <td>1904-01-01 11:38:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Origin Time  Latitude  Longitude  Depth(km)   xM   MD   ML  \\\n",
       "0  1900.09.20  00:00:01.00      37.8       29.1        5.0  5.0  5.0  0.0   \n",
       "1  1904.01.01  11:38:00.00      37.8       29.1       20.0  4.9  4.8  4.8   \n",
       "\n",
       "    Mw   Ms   Mb Type                                Location     City  \\\n",
       "0  NaN  0.0  0.0   Ke  DENIZLI (DENIZLI) [North East  2.3 km]  DENIZLI   \n",
       "1  4.9  4.8  4.9   Ke  DENIZLI (DENIZLI) [North East  2.3 km]  DENIZLI   \n",
       "\n",
       "   is_out_of_Turkey  id              ID_   NAME1_   NAME2_  PARTS_  POINTS_  \\\n",
       "0             False NaN  ASITUR003002002  Denizli  Denizli       1      164   \n",
       "1             False NaN  ASITUR003002002  Denizli  Denizli       1      164   \n",
       "\n",
       "    LENGTH_     AREA_           geometry           Direction  \\\n",
       "0  364.9901  4621.875  POINT (29.1 37.8)  North East  2.3 km   \n",
       "1  364.9901  4621.875  POINT (29.1 37.8)  North East  2.3 km   \n",
       "\n",
       "            Date_Time  \n",
       "0 1900-09-20 00:00:01  \n",
       "1 1904-01-01 11:38:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"final.csv\",sep=\",\", index_col=0) #, encoding='cp1252') \n",
    "df[\"Date_Time\"] = pd.to_datetime(df.Date +\" \"+ df[\"Origin Time\"])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482f7950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962241a8",
   "metadata": {},
   "source": [
    "#### Inspecting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf058e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Dtype</th>\n",
       "      <th># Unique Values</th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Date</td>\n",
       "      <td>object</td>\n",
       "      <td>13081</td>\n",
       "      <td>[2011.10.23, 2011.10.24, 2002.02.03, 2011.10.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Origin Time</td>\n",
       "      <td>object</td>\n",
       "      <td>40210</td>\n",
       "      <td>[00:00:01.00, 00:00:00.00, 11:15:05.00, 09:12:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>12914</td>\n",
       "      <td>[39.0, 37.0, 39.3, 39.1, 39.4, 37.1, 40.7, 39....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>18058</td>\n",
       "      <td>[29.1, 29.5, 29.0, 29.3, 27.7, 29.4, 29.2, 27....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Depth(km)</td>\n",
       "      <td>float64</td>\n",
       "      <td>577</td>\n",
       "      <td>[5.0, 10.0, 0.0, 8.0, 6.0, 7.0, 9.0, 1.0, 4.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xM</td>\n",
       "      <td>float64</td>\n",
       "      <td>46</td>\n",
       "      <td>[3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MD</td>\n",
       "      <td>float64</td>\n",
       "      <td>41</td>\n",
       "      <td>[0.0, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ML</td>\n",
       "      <td>float64</td>\n",
       "      <td>46</td>\n",
       "      <td>[0.0, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mw</td>\n",
       "      <td>float64</td>\n",
       "      <td>46</td>\n",
       "      <td>[nan, 3.2, 3.3, 3.1, 0.0, 3.4, 3.0, 3.5, 3.8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ms</td>\n",
       "      <td>float64</td>\n",
       "      <td>43</td>\n",
       "      <td>[0.0, 4.5, 4.6, 4.8, 4.7, 4.2, 4.0, 4.9, 5.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mb</td>\n",
       "      <td>float64</td>\n",
       "      <td>41</td>\n",
       "      <td>[0.0, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 4.6, 3.6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Type</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "      <td>[Ke, Sm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Location</td>\n",
       "      <td>object</td>\n",
       "      <td>35345</td>\n",
       "      <td>[VAN GÖLÜ, IZMIR KÖRFEZI (EGE DENIZI), GÖKOVA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>City</td>\n",
       "      <td>object</td>\n",
       "      <td>82</td>\n",
       "      <td>[DENIZLI, MANISA, KUTAHYA, MUGLA, VAN, IZMIR, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is_out_of_Turkey</td>\n",
       "      <td>bool</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>id</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ID_</td>\n",
       "      <td>object</td>\n",
       "      <td>81</td>\n",
       "      <td>[ASITUR003002002, ASITUR003003003, ASITUR00B00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NAME1_</td>\n",
       "      <td>object</td>\n",
       "      <td>81</td>\n",
       "      <td>[Denizli, Kutahya, Van, Balikesir, Manisa, Mug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NAME2_</td>\n",
       "      <td>object</td>\n",
       "      <td>80</td>\n",
       "      <td>[Denizli, Kütahya, Van, Balıkesir, Manisa, Muğ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PARTS_</td>\n",
       "      <td>int64</td>\n",
       "      <td>8</td>\n",
       "      <td>[1, 13, 18, 10, 5, 9, 3, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>POINTS_</td>\n",
       "      <td>int64</td>\n",
       "      <td>72</td>\n",
       "      <td>[164, 143, 348, 661, 171, 1688, 1072, 169, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LENGTH_</td>\n",
       "      <td>float64</td>\n",
       "      <td>81</td>\n",
       "      <td>[364.9901, 326.1353, 452.911, 645.6878, 370.36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AREA_</td>\n",
       "      <td>float64</td>\n",
       "      <td>81</td>\n",
       "      <td>[4621.875, 4711.23, 7238.176, 5729.821, 5115.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>geometry</td>\n",
       "      <td>object</td>\n",
       "      <td>37548</td>\n",
       "      <td>[POINT (29.5 37), POINT (29.4 37), POINT (30 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Direction</td>\n",
       "      <td>object</td>\n",
       "      <td>1331</td>\n",
       "      <td>[nan, South West  1.8 km, South West  1.6 km, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Date_Time</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>40626</td>\n",
       "      <td>[1900-09-20 00:00:01, 1995-01-31 22:53:22.2000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Variable           Dtype # Unique Values  \\\n",
       "0               Date          object           13081   \n",
       "1        Origin Time          object           40210   \n",
       "2           Latitude         float64           12914   \n",
       "3          Longitude         float64           18058   \n",
       "4          Depth(km)         float64             577   \n",
       "5                 xM         float64              46   \n",
       "6                 MD         float64              41   \n",
       "7                 ML         float64              46   \n",
       "8                 Mw         float64              46   \n",
       "9                 Ms         float64              43   \n",
       "10                Mb         float64              41   \n",
       "11              Type          object               2   \n",
       "12          Location          object           35345   \n",
       "13              City          object              82   \n",
       "14  is_out_of_Turkey            bool               2   \n",
       "15                id         float64               0   \n",
       "16               ID_          object              81   \n",
       "17            NAME1_          object              81   \n",
       "18            NAME2_          object              80   \n",
       "19            PARTS_           int64               8   \n",
       "20           POINTS_           int64              72   \n",
       "21           LENGTH_         float64              81   \n",
       "22             AREA_         float64              81   \n",
       "23          geometry          object           37548   \n",
       "24         Direction          object            1331   \n",
       "25         Date_Time  datetime64[ns]           40626   \n",
       "\n",
       "                                               Values  \n",
       "0   [2011.10.23, 2011.10.24, 2002.02.03, 2011.10.2...  \n",
       "1   [00:00:01.00, 00:00:00.00, 11:15:05.00, 09:12:...  \n",
       "2   [39.0, 37.0, 39.3, 39.1, 39.4, 37.1, 40.7, 39....  \n",
       "3   [29.1, 29.5, 29.0, 29.3, 27.7, 29.4, 29.2, 27....  \n",
       "4   [5.0, 10.0, 0.0, 8.0, 6.0, 7.0, 9.0, 1.0, 4.0,...  \n",
       "5   [3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, ...  \n",
       "6   [0.0, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, ...  \n",
       "7   [0.0, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, ...  \n",
       "8   [nan, 3.2, 3.3, 3.1, 0.0, 3.4, 3.0, 3.5, 3.8, ...  \n",
       "9   [0.0, 4.5, 4.6, 4.8, 4.7, 4.2, 4.0, 4.9, 5.0, ...  \n",
       "10  [0.0, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 4.6, 3.6, ...  \n",
       "11                                           [Ke, Sm]  \n",
       "12  [VAN GÖLÜ, IZMIR KÖRFEZI (EGE DENIZI), GÖKOVA ...  \n",
       "13  [DENIZLI, MANISA, KUTAHYA, MUGLA, VAN, IZMIR, ...  \n",
       "14                                      [False, True]  \n",
       "15                                              [nan]  \n",
       "16  [ASITUR003002002, ASITUR003003003, ASITUR00B00...  \n",
       "17  [Denizli, Kutahya, Van, Balikesir, Manisa, Mug...  \n",
       "18  [Denizli, Kütahya, Van, Balıkesir, Manisa, Muğ...  \n",
       "19                        [1, 13, 18, 10, 5, 9, 3, 8]  \n",
       "20  [164, 143, 348, 661, 171, 1688, 1072, 169, 200...  \n",
       "21  [364.9901, 326.1353, 452.911, 645.6878, 370.36...  \n",
       "22  [4621.875, 4711.23, 7238.176, 5729.821, 5115.7...  \n",
       "23  [POINT (29.5 37), POINT (29.4 37), POINT (30 3...  \n",
       "24  [nan, South West  1.8 km, South West  1.6 km, ...  \n",
       "25  [1900-09-20 00:00:01, 1995-01-31 22:53:22.2000...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = pd.DataFrame(columns=['Variable',\"Dtype\", '# Unique Values','Values'])\n",
    "\n",
    "for i, var in enumerate(df.columns):\n",
    "    variables.loc[i] = [var, df[var].dtype, df[var].nunique(), \n",
    "                        df[var].value_counts(dropna=False).index.tolist()]    ## Values are sorted according to their frequency in the data\n",
    "variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296027d",
   "metadata": {},
   "source": [
    "* xM, MD, ML, Mw, Ms, Mb : contains values of different magnitude types. We will be keeping all of them at this stage. (For the other projects published on the web (Kaggle, Medium etc.) and data visualizations on koeri.boun.edu web page xM is used as the Magnitude variable. We also asked Gijs (on slack) to understand if Mw is the actual Magnitude variable. ) \n",
    "* Type column indicates whether the observation is an earthquake (Ke) or any suspected explosion (Sm). --- We will binary encode it as we discussed on the last meeting.\n",
    "* Location will be kept for EDA process, and will be dropped during modeling. \n",
    "* is_out_of_Turkey was built by using the details in Location column, after using geopandas it became redundant and will be removed.\n",
    "* id column has nan values for all records and will be removed.\n",
    "* City, NAME1_ and NAME2_ contain city values. The difference between NAME1_ and NAME2_ is NAME2_contains Turkish characters (like ü,ğ ...). City is a feature obtained by getting city names from Location column and NAME1_, NAME2_ are obtained from geopandas. As we agreed on the meeting 20th of July, for the records which have inconsistencies in City and NAME1_ features we will use geopy library to get the City values. \n",
    "* As we agreed on the meeting 20th of July, the geopandas features ID_, LENGTH_, PARTS_, POINTS_ will be removed.\n",
    "* AREA and geometry will be kept for modeling (as we agreed on the meeting 20th of July).\n",
    "* \"Direction\" will be removed from the data set, as we have discussed in the meeting on 24th of July."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e67e722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"Date\",\"Origin Time\",\"is_out_of_Turkey\",\"id\",\"NAME1_\",\"NAME2_\",\n",
    "                \"ID_\", \"LENGTH_\", \"PARTS_\", \"POINTS_\", \"Direction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dcdfd",
   "metadata": {},
   "source": [
    "### Appending the records which are near to Turkey but filtered out by geopandas \n",
    "As we have agreed on the meetings on 20th and 24th of July...\n",
    "\n",
    "For detailed explanation please check the \"Omdena_Turkey_chapter__Preprocess.ipynb\" file shared on slack (task-1-data channel on 20th of July).\n",
    "\n",
    "Loading the previous dataset (containing all records both inside and outide of Turkey): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7769f035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Origin Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Depth(km)</th>\n",
       "      <th>xM</th>\n",
       "      <th>MD</th>\n",
       "      <th>ML</th>\n",
       "      <th>Mw</th>\n",
       "      <th>Ms</th>\n",
       "      <th>Mb</th>\n",
       "      <th>Type</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>is_out_of_Turkey</th>\n",
       "      <th>Date_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19000920000001</td>\n",
       "      <td>1900.09.20</td>\n",
       "      <td>00:00:01.00</td>\n",
       "      <td>37.8</td>\n",
       "      <td>29.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ke</td>\n",
       "      <td>DENIZLI (DENIZLI) [North East  2.3 km]</td>\n",
       "      <td>DENIZLI</td>\n",
       "      <td>False</td>\n",
       "      <td>1900-09-20 00:00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Event ID        Date  Origin Time  Latitude  Longitude  Depth(km)  \\\n",
       "0  19000920000001  1900.09.20  00:00:01.00      37.8       29.1        5.0   \n",
       "\n",
       "    xM   MD   ML  Mw   Ms   Mb Type                                Location  \\\n",
       "0  5.0  5.0  0.0 NaN  0.0  0.0   Ke  DENIZLI (DENIZLI) [North East  2.3 km]   \n",
       "\n",
       "      City  is_out_of_Turkey           Date_Time  \n",
       "0  DENIZLI             False 1900-09-20 00:00:01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre = pd.read_csv(r\"Turkey_earthquakes_koeri_1900_2022_rev1.csv\",sep=\",\", index_col=0) #, encoding='cp1252') \n",
    "df_pre[\"Date_Time\"] = pd.to_datetime(df_pre.Date +\" \"+ df_pre[\"Origin Time\"])\n",
    "df_pre.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f982741",
   "metadata": {},
   "source": [
    "Filtering the records of previous data set which are in Turkey or in Marmara Sea (according to the \"Location\" column of the dataset): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34057421",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42823"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## getting Date_Time values of the earthquakes as the unique idenditifers\n",
    "## Earthquakes in Turkey according to the Location column\n",
    "in_TR_pre = set(df_pre.loc[df_pre.is_out_of_Turkey==False, \"Date_Time\"])\n",
    "\n",
    "### Earthquakes in Marmara Sea\n",
    "in_Marmara = df_pre.loc[df_pre.Location.str.contains(\"MARMARA\"), \"Date_Time\"]\n",
    "\n",
    "in_TR_pre.update(in_Marmara)   ## all earthquakes in Turkey (according to the Location column)\n",
    "len(in_TR_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9f717",
   "metadata": {},
   "source": [
    "Comparing its unique identifier (Date_Time) with the final.csv df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33aa5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2806"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all unique records in final.csv\n",
    "in_TR_Final = set(df[\"Date_Time\"])\n",
    "\n",
    "# earthquake ids that are in previous df but not in final.csv:\n",
    "in_pre_but_not_in_final = in_TR_pre - in_TR_Final\n",
    "len(in_pre_but_not_in_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d87f3",
   "metadata": {},
   "source": [
    "The below code block creates the data set of 2806 records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d465361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_get_geopandas_feats = df_pre.loc[(df_pre.Date_Time.isin(in_pre_but_not_in_final))]\n",
    "# df_to_get_geopandas_feats.to_csv(\"records_to_add_geopandas_feats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea91572",
   "metadata": {},
   "source": [
    "##### Appending these 2806 records and appending to dataset\n",
    "To append these records to our dataset we need to create the same features as df..\n",
    "\n",
    "I used the code below to get the geopandas features, but since these earthquakes are outside of Turkey geopandas bring NAN values for all features (so there is no need to use below code). We will append 2806 records to our data and will be imputing them in \"Handling missing values\" section."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c84100a",
   "metadata": {},
   "source": [
    "#### Getting geopandas features for these 2806 records\n",
    "import geopandas\n",
    "\n",
    "gdf = geopandas.GeoDataFrame(df_to_get_geopandas_feats, \n",
    "           geometry=geopandas.points_from_xy(df_to_get_geopandas_feats.Longitude, df_to_get_geopandas_feats.Latitude))\n",
    "\n",
    "dfgeopandas_TR = geopandas.read_file(r'Geojson\\Turkiye_Geojon.json')\n",
    "df_to_get_geopandas_feats = geopandas.overlay(gdf, dfgeopandas_TR, how='union')\n",
    "df_to_get_geopandas_feats.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e010628d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_to_get_geopandas_feats.drop(\"Event ID\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dc2e34a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.append(df_to_get_geopandas_feats, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0595c",
   "metadata": {},
   "source": [
    "### Deciding the feature to be used as Magnitude value\n",
    "We will be keeping all of the magnitude features in our dataset (at this stage). I would like to keep the text below to share how others selected the target (magnitude) variable.\n",
    "\n",
    "Accoridng to http://www.koeri.boun.edu.tr/sismo/2/earthquake-catalog/ wep page:\n",
    "* xM : Biggest magnitude value in specified magnitude values (MD, ML, Mw, Ms and Mb).\n",
    "* MD, ML, Mw, Ms or Mb : Magnitude types (MD: Duration, ML: Local, Mw: Moment, Ms: Surface wave, Mb: Body-wave). 0.0 (zero) means no calculation for that type of magnitude.\n",
    "\n",
    "As I understand form the last statement on that web page (the last sentence of 3.b), using xM as the magnitude metric will be reasonable. Because the data provider used this feature on their visualiztion.\n",
    "\n",
    "Also on the blog articles below, \"xM\" has been used as the Magnitude variable:\n",
    "* [Turkey Earthquake Analysis (1915-2020) - Ata Saygin](https://www.kaggle.com/code/atasaygin/turkey-earthquake-analysis-1915-2020)\n",
    "* [Explanatory Analysis of the Earthquakes in Turkey - Nilay Cicekli](https://github.com/nilaycicekli/earthquake-EDA-turkey/blob/master/Earthquake%20Analysis.ipynb)\n",
    "* [Earthquake Parameter Prediction with Linear Regression - Fatma Elik](https://medium.com/analytics-vidhya/earthquake-parameter-prediction-with-linear-regression-c86e5abff79f) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a8170b6",
   "metadata": {},
   "source": [
    "df[\"Magnitude\"] = df.xM.copy()\n",
    "\n",
    "cols_to_drop.extend(['xM', 'MD', 'ML',  'Ms', 'Mb'])  ##  For 'Mw' we are waiting a response from Gijs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c9c83",
   "metadata": {},
   "source": [
    "#### Binary encoding of Type feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "419c0a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ke    0.997375\n",
       "Sm    0.002625\n",
       "Name: Type, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Type.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f74e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Type = df.Type.map({\"Ke\":1,\"Sm\":0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7454894",
   "metadata": {},
   "source": [
    "### Building a reliable City Feature\n",
    "City feature on the data set is obtianed from Location column and NAME1_ is obtianed from geopandas library. As seen below they have inconsistencies in 10057 records. As agreed on 20th of July we will use geopy library to get reliable City values for the records having that inconsistency problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf1f6f3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10057, 26)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.NAME1_.str.lower() != df.City.str.lower()].shape    #head(20) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9fb73",
   "metadata": {},
   "source": [
    "We will copy city values obtained from Location column to City_Location, and create a new City column having the proper City values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "608cf5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"City_Location\"] = df[\"City\"].copy()\n",
    "df[\"City\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec297667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the indexes with City values having inconsistency problem or not\n",
    "rows_city_location_is_okay = df.loc[df.NAME1_.str.lower() == df.City_Location.str.lower()].index\n",
    "rows_use_geopy_for_city    = df.loc[df.NAME1_.str.lower() != df.City_Location.str.lower()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86cb4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the records having same value in City_Location and NAME1_:\n",
    "df.loc[rows_city_location_is_okay, \"City\"] = df[\"City_Location\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee1a30d",
   "metadata": {},
   "source": [
    "#### Using Geopy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e94eef9",
   "metadata": {},
   "source": [
    "Below I couldn't get city values for all records (43K) because it took about 1.5 hours for 10K records to get the location detials from the api (geoapiExercises). That's why I got only the ones having inconsitencies between City and NAME1_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d93e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7367f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Nominatim API\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1319cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"geopy_location\"] =np.nan\n",
    "\n",
    "for index, row in df.loc[rows_use_geopy_for_city].iterrows():\n",
    "    df.loc[index ,\"geopy_location\"] = str(geolocator.reverse(str(row.Latitude)+\",\"+str(row.Longitude)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d340f31",
   "metadata": {},
   "source": [
    "df.to_csv(\"df_geopy_location_backup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5ee5008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10057"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.geopy_location.notnull()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28716e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city(geopy_output):\n",
    "    geopy_output_value = str(geopy_output)\n",
    "    end_of_region   = geopy_output_value.find(\"Bölgesi\")\n",
    "    start_of_region = geopy_output_value[:end_of_region].rfind(\",\") \n",
    "    \n",
    "    start_of_city   = geopy_output_value[:start_of_region].rfind(\",\")+1\n",
    "    geopy_output_value[start_of_city : start_of_region].strip() \n",
    "    city = geopy_output_value[start_of_city : start_of_region].strip()\n",
    "    return city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "827e591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[rows_use_geopy_for_city, \"City\"]= df[\"geopy_location\"].apply(get_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a0970d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "پارێزگای ئازەربایجانی ڕۆژاوا    152\n",
       "ھەرێمی کوردستان                  59\n",
       "685 00                           18\n",
       "Շիրակի մարզ                      15\n",
       "محافظة إدلب                      12\n",
       "Name: City, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df[\"geopy_location\"].notnull()) \n",
    "       & (df[\"geopy_location\"].str.find(\"Bölgesi\")==-1),\"City\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2e15e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[(df[\"geopy_location\"].notnull()) \n",
    "       & (df[\"geopy_location\"].str.find(\"Bölgesi\")==-1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620dd849",
   "metadata": {},
   "source": [
    "There are 394 records of which city names obtained from geopy are not Turkish. Replacing them with the values in City_Locaiton column (obtained from the Location column) may be reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb4195ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.loc[(df[\"geopy_location\"].notnull()) \n",
    "                   & (df[\"geopy_location\"].str.find(\"Bölgesi\")==-1)].iterrows():\n",
    "    \n",
    "    if row[\"City_Location\"] != \"out_of_Turkey\":     \n",
    "        df.loc[index ,\"City\"] = row[\"City_Location\"]  \n",
    "    elif row[\"NAME1_\"]!=np.nan:\n",
    "        df.loc[index ,\"City\"] = row[\"NAME1_\"].upper()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c3e2867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"City\"] = df[\"City\"].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2baac852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.City = (df.City.str.replace(\"i\",\"I\").str.replace(\"İ\",\"I\")\n",
    "             .str.replace(\"Ö\",\"O\")\n",
    "             .str.replace(\"Ü\",\"U\")\n",
    "             .str.replace(\"Ç\",\"C\")\n",
    "             .str.replace(\"Ğ\",\"G\")\n",
    "             .str.replace(\"Â\",\"A\")\n",
    "             .str.replace(\"Ş\",\"S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57f4a018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADANA',\n",
       " 'ADIYAMAN',\n",
       " 'AFYONKARAHISAR',\n",
       " 'AGRI',\n",
       " 'AKSARAY',\n",
       " 'AMASYA',\n",
       " 'ANKARA',\n",
       " 'ANTALYA',\n",
       " 'ARDAHAN',\n",
       " 'ARTVIN',\n",
       " 'AYDIN',\n",
       " 'BALIKESIR',\n",
       " 'BARTIN',\n",
       " 'BATMAN',\n",
       " 'BAYBURT',\n",
       " 'BILECIK',\n",
       " 'BINGOL',\n",
       " 'BITLIS',\n",
       " 'BOLU',\n",
       " 'BURDUR',\n",
       " 'BURSA',\n",
       " 'CANAKKALE',\n",
       " 'CANKIRI',\n",
       " 'CORUM',\n",
       " 'DENIZLI',\n",
       " 'DIYARBAKIR',\n",
       " 'DUZCE',\n",
       " 'EDIRNE',\n",
       " 'ELAZIG',\n",
       " 'ERZINCAN',\n",
       " 'ERZURUM',\n",
       " 'ESKISEHIR',\n",
       " 'GAZIANTEP',\n",
       " 'GIRESUN',\n",
       " 'GUMUSHANE',\n",
       " 'HAKKARI',\n",
       " 'HATAY',\n",
       " 'IGDIR',\n",
       " 'ISPARTA',\n",
       " 'ISTANBUL',\n",
       " 'IZMIR',\n",
       " 'IZMIR-USAK YOLU',\n",
       " 'KAHRAMANMARAS',\n",
       " 'KALE',\n",
       " 'KAPISUYU',\n",
       " 'KARABUK',\n",
       " 'KARAMAN',\n",
       " 'KARS',\n",
       " 'KASTAMONU',\n",
       " 'KAYSERI',\n",
       " 'KILIS',\n",
       " 'KIRIKKALE',\n",
       " 'KIRKLARELI',\n",
       " 'KIRSEHIR',\n",
       " 'KOCAELI',\n",
       " 'KONYA',\n",
       " 'KUTAHYA',\n",
       " 'MALATYA',\n",
       " 'MANISA',\n",
       " 'MARDIN',\n",
       " 'MERSIN',\n",
       " 'MEYDAN',\n",
       " 'MUGLA',\n",
       " 'MUS',\n",
       " 'NEVSEHIR',\n",
       " 'NIGDE',\n",
       " 'ORDU',\n",
       " 'OSMANIYE',\n",
       " 'RIZE',\n",
       " 'SAKARYA',\n",
       " 'SAMSUN',\n",
       " 'SANLIURFA',\n",
       " 'SIIRT',\n",
       " 'SINOP',\n",
       " 'SIRNAK',\n",
       " 'SIVAS',\n",
       " 'TEKIRDAG',\n",
       " 'TOKAT',\n",
       " 'TRABZON',\n",
       " 'TUNCELI',\n",
       " 'TURKIY',\n",
       " 'USAK',\n",
       " 'VAN',\n",
       " 'YALOVA',\n",
       " 'YAYIKDAMLAR',\n",
       " 'YOZGAT',\n",
       " 'ZONGULDAK']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(df.City.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb883663",
   "metadata": {},
   "source": [
    "According to the output above some recoreds have city names as 'IZMIR-USAK YOLU','KALE','KAPISUYU','KAPISUYU','TURKIY','YAYIKDAMLAR','MEYDAN'. They are actually not cities in Turkey. They need to be replaced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8266bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_city_names = ['IZMIR-USAK YOLU','KALE','KAPISUYU','MEYDAN','TURKIY','YAYIKDAMLAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b77cb503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IZMIR', 'ANTALYA', 'HATAY'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.City.isin(wrong_city_names), \"City_Location\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d9269",
   "metadata": {},
   "source": [
    "So their City values will be replaced with City_Location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f15b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.City.isin(wrong_city_names), \"City\"] = df[\"City_Location\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdf6d1f",
   "metadata": {},
   "source": [
    "##### Replacing AREA_ values according to new City names\n",
    "AREA_ is the feature generated by geopandas and it shows the AREA_ values of each cities (as we understand from the data). Above we have changed city values of 10K records and we need to change their AREA_ values, too (assign the AREA_ values of their new City values):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce5e539",
   "metadata": {},
   "source": [
    "Before starting we will create a backup feature for AREA_ as AREA_backup and will drop it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "589be8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AREA_backup\"] = df[\"AREA_\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57995915",
   "metadata": {},
   "source": [
    "Getting the correct city and area matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7926e96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "city_area_matches = df.loc[rows_city_location_is_okay, [\"City\",\"AREA_\"]]  \\\n",
    "                                .drop_duplicates().set_index(\"City\").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cd18549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[rows_use_geopy_for_city,\"AREA_\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1386d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in df.loc[rows_use_geopy_for_city].iterrows():\n",
    "    try:\n",
    "        area_of_city = city_area_matches['AREA_'][row[\"City\"]]    \n",
    "        df.loc[index, \"AREA_\"] = area_of_city\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62811fd",
   "metadata": {},
   "source": [
    "Verifying if any record had problem with imputation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11f62498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AFYONKARAHISAR'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.AREA_.isnull(), \"City\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec32e590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFYONKARAHISAR'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.City) - set(df.loc[rows_city_location_is_okay,\"City\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb215d8",
   "metadata": {},
   "source": [
    "AFYONKARAHISAR (or AFYON) is not in the records of rows_city_location_is_okay, we need to get it manually. It is stated as Afyon in NAME1_ column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fb334c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5760.035])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.NAME1_==\"Afyon\", \"AREA_backup\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "289b8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.City==\"AFYONKARAHISAR\", \"AREA_\"] = 5760.035"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f0849",
   "metadata": {},
   "source": [
    "The features built during the process of getting the city names will de dropped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9891b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop.extend([\"City_Location\",\"geopy_location\",\"AREA_backup\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72675ed6",
   "metadata": {},
   "source": [
    "#### Extracting Date and Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53663358",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year\"]  = df.Date_Time.dt.year\n",
    "df[\"Month\"] = df.Date_Time.dt.month\n",
    "df[\"Hour\"]  = df.Date_Time.dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6121d7",
   "metadata": {},
   "source": [
    "### Dropping the unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc878511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Origin Time',\n",
       " 'is_out_of_Turkey',\n",
       " 'id',\n",
       " 'NAME1_',\n",
       " 'NAME2_',\n",
       " 'ID_',\n",
       " 'LENGTH_',\n",
       " 'PARTS_',\n",
       " 'POINTS_',\n",
       " 'Direction',\n",
       " 'City_Location',\n",
       " 'geopy_location',\n",
       " 'AREA_backup']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db4fdc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Depth(km)</th>\n",
       "      <th>xM</th>\n",
       "      <th>MD</th>\n",
       "      <th>ML</th>\n",
       "      <th>Mw</th>\n",
       "      <th>Ms</th>\n",
       "      <th>Mb</th>\n",
       "      <th>Type</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>AREA_</th>\n",
       "      <th>geometry</th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.8</td>\n",
       "      <td>29.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>DENIZLI (DENIZLI) [North East  2.3 km]</td>\n",
       "      <td>DENIZLI</td>\n",
       "      <td>4621.875</td>\n",
       "      <td>POINT (29.1 37.8)</td>\n",
       "      <td>1900-09-20 00:00:01</td>\n",
       "      <td>1900</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Latitude  Longitude  Depth(km)   xM   MD   ML  Mw   Ms   Mb  Type  \\\n",
       "0      37.8       29.1        5.0  5.0  5.0  0.0 NaN  0.0  0.0     1   \n",
       "\n",
       "                                 Location     City     AREA_  \\\n",
       "0  DENIZLI (DENIZLI) [North East  2.3 km]  DENIZLI  4621.875   \n",
       "\n",
       "            geometry           Date_Time  Year  Month  Hour  \n",
       "0  POINT (29.1 37.8) 1900-09-20 00:00:01  1900      9     0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(cols_to_drop,axis=1, inplace=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e20cd81",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa2f3a5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latitude         0\n",
       "Longitude        0\n",
       "Depth(km)        0\n",
       "xM               0\n",
       "MD               0\n",
       "ML               0\n",
       "Mw           37659\n",
       "Ms               0\n",
       "Mb               0\n",
       "Type             0\n",
       "Location         0\n",
       "City             0\n",
       "AREA_            0\n",
       "geometry      2806\n",
       "Date_Time        0\n",
       "Year             0\n",
       "Month            0\n",
       "Hour             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c1a6e9",
   "metadata": {},
   "source": [
    "'geometry' is the geopandas features, they are null for the 2806 records we appended above. We can impute them by cretaing the same structure we observed on the non-null records.  (AREA_ is the other geopandas feature, for the 2806 records we don't see NaN here because updated them above..)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334608d",
   "metadata": {},
   "source": [
    "Creating the \"geometry\" feature values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eacb00a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in df.loc[df.geometry.isnull()].iterrows():\n",
    "    ## Building exactly the same structure as \"geometry\" column of geopandas\n",
    "    long = int(row[\"Longitude\"]) if (row[\"Longitude\"]).is_integer() else row[\"Longitude\"]\n",
    "    lat  = int(row[\"Latitude\"]) if (row[\"Latitude\"]).is_integer() else row[\"Latitude\"]\n",
    "    \n",
    "    df.loc[index, \"geometry\"] = \"POINT (\"+str(long)+\" \"+str(lat)+\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "646d111b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8670795726653159"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Mw.isnull().sum() / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b9e46d",
   "metadata": {},
   "source": [
    "86% of records have null vaue in MW. I left them as is for now, because couldn't figure out how to impyte in a proper way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a630c61",
   "metadata": {},
   "source": [
    "### Getting last version of the dataset -- csv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ababbaf",
   "metadata": {},
   "source": [
    "df.to_csv(\"Omdena_Turkey__final_rev1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
